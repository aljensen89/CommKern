% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NMI.R
\name{NMI}
\alias{NMI}
\title{Normalized mutual information (NMI)}
\usage{
NMI(a, b, variant = c("max", "min", "sqrt", "sum", "joint"))
}
\arguments{
\item{a}{a vector of classifications; this must be a vector of characters, integers, numerics, or a factor, but not a list.}

\item{b}{a vector of classifications}

\item{variant}{a string in ('max', 'min', 'sqrt', 'sum', 'joint') that calculates different variants of the NMI.
The default use is 'max'.}
}
\value{
res, a scalar with the normalized mutual information (NMI).
}
\description{
Description of the normalized mutual information function.
}
\details{
In information theory, the mutual information (MI) of two random variables is a measure of the
mutual dependence between two variables, or the quantification of the 'amount of information' obtained
about one random variable by observing the other random variable. The normalization of the MI score scales
the resuts between 0 (no mutual information) and 1 (perfect correlation).
}
